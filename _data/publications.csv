Sr_No,Contact,Paper,Link,Google_Scholar_Link,Year,Author_Names,Citation,
1,Vasileios Charisopoulos,Nonlinear tomographic reconstruction via nonsmooth optimization,https://epubs.siam.org/doi/10.1137/24M1678982,https://scholar.google.com/citations?user=X3V6rM8AAAAJ&hl=el,2025,"Charisopoulos, V., & Willett, R.","Charisopoulos, V., & Willett, R. (2025). Nonlinear tomographic reconstruction via nonsmooth optimization. SIAM Journal on Mathematics of Data Science, 7(2), 699–722.",TRUE
2,Vasileios Charisopoulos,Solving Inverse Problems with Deep Linear Neural Networks: Global Convergence Guarantees for Gradient Descent with Weight Decay,https://arxiv.org/abs/2502.15522,https://scholar.google.com/citations?user=X3V6rM8AAAAJ&hl=el,2025,"Laus, H., Parkinson, S., Charisopoulos, V., Krahmer, F., & Willett, R.","Laus, H., Parkinson, S., Charisopoulos, V., Krahmer, F., & Willett, R. (2025). Solving inverse problems with deep linear neural networks: Global convergence guarantees for gradient descent with weight decay (arXiv preprint arXiv:2502.15522).",FALSE
3,David Reber,RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals,https://openreview.net/forum?id=rL3uxe5a0c,https://scholar.google.com/citations?hl=en&user=8MXWn9gAAAAJ&view_op=list_works&sortby=pubdate,2025,"Reber, D., Richardson, S. M., Nief, T., Garbacea, C., & Veitch, V.","Reber, D., Richardson, S. M., Nief, T., Garbacea, C., & Veitch, V. (2025). RATE: Causal explainability of reward models with imperfect counterfactuals. In Proceedings of the Forty-second International Conference on Machine Learning.",TRUE
4,Yibo Jiang,The geometry of categorical and hierarchical concepts in large language models,https://openreview.net/forum?id=bVTM2QKYuA,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2025,"Park, K., Choe, Y. J., Jiang, Y., & Veitch, V.","Park, K., Choe, Y. J., Jiang, Y., & Veitch, V. (2025). The geometry of categorical and hierarchical concepts in large language models. In Proceedings of the International Conference on Learning Representations (ICLR) (oral presentation).",TRUE
5,Yibo Jiang,On the origins of linear representations in large language models,https://proceedings.mlr.press/v235/jiang24d.html,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2024,"Jiang, Y., Rajendran, G., Ravikumar, P. K., Aragam, B., & Veitch, V.","Jiang, Y., Rajendran, G., Ravikumar, P. K., Aragam, B., & Veitch, V. (2024). On the origins of linear representations in large language models. In Proceedings of the 41st International Conference on Machine Learning (pp. 21879–21911). PMLR.",TRUE
6,Yibo Jiang,Beyond reverse KL: Generalizing direct preference optimization with diverse divergence constraints,https://openreview.net/forum?id=2cRzmWXK9N,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2024,"Wang, C., Jiang, Y., Yang, C., Liu, H., & Chen, Y.","Wang, C., Jiang, Y., Yang, C., Liu, H., & Chen, Y. (2024). Beyond reverse KL: Generalizing direct preference optimization with diverse divergence constraints. In Proceedings of the International Conference on Learning Representations (ICLR) (Spotlight presentation).",TRUE
7,Yibo Jiang,Learning nonparametric latent causal graphs with unknown interventions,https://proceedings.neurips.cc/paper_files/paper/2023/file/bdeab378efe6eb289714e2a5abc6ed42-Paper-Conference.pdf,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2023,"Jiang, Y., & Aragam, B.","Jiang, Y., & Aragam, B. (2023). Learning nonparametric latent causal graphs with unknown interventions. In Advances in Neural Information Processing Systems, 36 (NeurIPS 2023).",TRUE
8,Yibo Jiang,Uncovering meanings of embeddings via partial orthogonality,https://proceedings.neurips.cc/paper_files/paper/2023/file/65a925049647eab0aa06a9faf1cd470b-Paper-Conference.pdf,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2023,"Jiang, Y., Aragam, B., & Veitch, V.","Jiang, Y., Aragam, B., & Veitch, V. (2023). Uncovering meanings of embeddings via partial orthogonality. In Advances in Neural Information Processing Systems (NeurIPS 2023), 36 (pp. ...).",TRUE
9,Chacha Chen,CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation,https://arxiv.org/abs/2505.16325,https://scholar.google.com/citations?hl=zh-TW&user=X1c-e4oAAAAJ&view_op=list_works&sortby=pubdate,2025,"Jiang, Y., Chen, C., Wang, S., Li, F., Tang, Z., Mervak, B. M., Chelala, L., Straus, C. M., Chahine, R., Armato, S. G. III, & Tan, C.","Jiang, Y., Chen, C., Wang, S., Li, F., Tang, Z., Mervak, B. M., Chelala, L., Straus, C. M., Chahine, R., Armato, S. G. III, & Tan, C. (2025). CLEAR: A clinically-grounded tabular framework for radiology report evaluation (arXiv:2505.16325). arXiv.",FALSE
10,Chacha Chen,Gpt-4v cannot generate radiology reports yet,https://arxiv.org/abs/2407.12176,https://scholar.google.com/citations?hl=zh-TW&user=X1c-e4oAAAAJ&view_op=list_works&sortby=pubdate,2024,"Jiang, Y., Chen, C., Nguyen, D., Mervak, B. M., & Tan, C.","Jiang, Y., Chen, C., Nguyen, D., Mervak, B. M., & Tan, C. (2024). Gpt-4v cannot generate radiology reports yet (arXiv:2407.12176). arXiv.",FALSE
11,Melissa Adrian,Stabilizing black-box model selection with the inflated argmax.,https://arxiv.org/abs/2410.18268,https://scholar.google.com/citations?hl=en&user=kFcLjtUAAAAJ&view_op=list_works&sortby=pubdate,2024,"Adrian, M., Soloff, J. A., & Willett, R.","Adrian, M., Soloff, J. A., & Willett, R. (2024). Stabilizing black-box model selection with the inflated argmax (arXiv:2410.18268). arXiv.",FALSE
12,Lin Gui,Concept algebra for (score-based) text-controlled generative models,https://proceedings.neurips.cc/paper_files/paper/2023/file/6f125214c86439d107ccb58e549e828f-Paper-Conference.pdf,https://scholar.google.com/citations?user=88eaL8UAAAAJ&hl=en,2023,"Wang, Z., Gui, L., Negrea, J., & Veitch, V.","Wang, Z., Gui, L., Negrea, J., & Veitch, V. (2023). Concept algebra for (score-based) text-controlled generative models. In Advances in Neural Information Processing Systems (Vol. 36, pp. 35331–35349).",TRUE
13,Lin Gui,Bonbon alignment for large language models and the sweetness of best-of-n sampling,https://proceedings.neurips.cc/paper_files/paper/2024/hash/056521a35eacd9d2127b66a7d3c499c5-Abstract-Conference.html,https://scholar.google.com/citations?user=88eaL8UAAAAJ&hl=en,2024,"Gui, L., Gârbacea, C., & Veitch, V.","Gui, L., Gârbacea, C., & Veitch, V. (2024). Bonbon alignment for large language models and the sweetness of best-of-n sampling (arXiv:2406.00832). arXiv",FALSE
14,Peter Lu,Hierarchical Implicit Neural Emulators,https://arxiv.org/abs/2506.04528,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2025,"Jiang, R., Zhang, X., Jakhar, K., Lu, P. Y., Hassanzadeh, P., Maire, M., & Willett, R.","Jiang, R., Zhang, X., Jakhar, K., Lu, P. Y., Hassanzadeh, P., Maire, M., & Willett, R. (2025). Hierarchical implicit neural emulators (arXiv:2506.04528). arXiv",FALSE
15,Peter Lu,Embed and Emulate: Contrastive representations for simulation-based inference,https://arxiv.org/abs/2409.18402,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2024,"Jiang, R., Lu, P. Y., & Willett, R.","Jiang, R., Lu, P. Y., & Willett, R. (2024). Embed and Emulate: Contrastive representations for simulation-based inference (arXiv:2409.18402). arXiv.",FALSE
16,Peter Lu,Training Machine Learning Emulators to Preserve Invariant Measures of Chaotic Attractors,https://ui.adsabs.harvard.edu/abs/2024APS..MARS28006L/abstract,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2024,"Lu, P., Jiang, R., Orlova, E., & Willett, R.","Lu, P., Jiang, R., Orlova, E., & Willett, R. (2024). Training machine learning emulators to preserve invariant measures of chaotic attractors. APS March Meeting Abstracts, 2024, S28.006.",TRUE
17,Peter Lu,Deep Stochastic Mechanics,https://arxiv.org/abs/2305.19685,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2023,"Orlova, E., Ustimenko, A., Jiang, R., Lu, P. Y., & Willett, R.","Orlova, E., Ustimenko, A., Jiang, R., Lu, P. Y., & Willett, R. (2023). Deep stochastic mechanics (arXiv:2305.19685). arXiv.",FALSE
18,Chenghao Yang,How Alignment Shrinks the Generative Horizon,https://arxiv.org/abs/2506.17871,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Yang, C., & Holtzman, A.","Yang, C., & Holtzman, A. (2025). How alignment shrinks the generative horizon. arXiv preprint arXiv:2506.17871.",FALSE
19,Chenghao Yang,Tokenized Bandit for LLM Decoding and Alignment,https://icml.cc/virtual/2025/poster/45185,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Shin, S., Yang, C., Xu, H., & Hajiaghayi, M. T.","Shin, S., Yang, C., Xu, H., & Hajiaghayi, M. T. (2025). Tokenized bandit for LLM decoding and alignment. In Proceedings of the 42nd International Conference on Machine Learning (ICML 2025). arXiv:2506.07276.",TRUE
20,Chenghao Yang,Grounded Persuasive Language Generation for Automated Marketing,https://arxiv.org/abs/2502.16810,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Wu, J., Yang, C., Mahns, S., Wang, C., Zhu, H., Fang, F., & Xu, H.","Wu, J., Yang, C., Mahns, S., Wang, C., Zhu, H., Fang, F., & Xu, H. (2025). Grounded persuasive language generation for automated marketing (arXiv:2502.16810). arXiv.",FALSE
21,Chenghao Yang,When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models (NAACL 2024 Findings),https://aclanthology.org/2024.findings-naacl.237/,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2024,"Li, Y., Yang, C., & Ettinger, A.","Li, Y., Yang, C., & Ettinger, A. (2024). When hindsight is not 20/20: Testing limits on reflective thinking in large language models. In Findings of the Association for Computational Linguistics: NAACL 2024. arXiv:2404.09129.",TRUE
22,Chenghao Yang,"Identifying Self-Disclosures of Use, Misuse and Addiction in Community-based Social Media Posts (NAACL 2024 Findings)",https://aclanthology.org/2024.findings-naacl.161/,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2024,"Yang, C., Chakrabarty, T., Hochstatter, K. R., Slavin, M. N., El‑Bassel, N., & Muresan, S.","Yang, C., Chakrabarty, T., Hochstatter, K. R., Slavin, M. N., El‑Bassel, N., & Muresan, S. (2024). Identifying self‑disclosures of use, misuse and addiction in community‑based social media posts. In Findings of the Association for Computational Linguistics: NAACL 2024 (pp. 2507–2521). Association for Computational Linguistics",TRUE
23,Chenghao Yang,Can You Follow Me? Testing Situational Understanding in ChatGPT (EMNLP 2023),https://aclanthology.org/2023.emnlp-main.394/,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2023,"Yang, C., & Ettinger, A.","Yang, C., & Ettinger, A. (2023). Can You Follow Me? Testing situational understanding in ChatGPT. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (pp. 6385–6398). Association for Computational Linguistics",TRUE
24,Xiaoyan Bai,Concept Incongruence: An Exploration of Time and Death in Role Playing,https://arxiv.org/abs/2505.14905,https://scholar.google.com/citations?hl=en&user=ic3BUhMAAAAJ&view_op=list_works&sortby=pubdate,2025,"Bai, X., Peng, I., Singh, A., & Tan, C.","Bai, X., Peng, I., Singh, A., & Tan, C. (2025). Concept incongruence: An exploration of time and death in role playing (arXiv:2505.14905). arXiv",FALSE
25,Akhil Premkumar,Diffusion Density Estimators,https://arxiv.org/abs/2410.06986,https://scholar.google.com/citations?hl=en&user=clBdLXkAAAAJ&view_op=list_works&sortby=pubdate,2024,"Premkumar, A.","Premkumar, A. (2024). Diffusion density estimators (arXiv:2410.06986). arXiv.",FALSE
26,Akhil Premkumar,Neural entropy,https://arxiv.org/abs/2409.03817,https://scholar.google.com/citations?hl=en&user=clBdLXkAAAAJ&view_op=list_works&sortby=pubdate,2024,"Premkumar, A.","Premkumar, A. (2024). Neural entropy (arXiv:2409.03817). arXiv.",FALSE
27,Mark Muchane,Incorporating Hierarchical Semantics in Sparse Autoencoder Architectures,https://arxiv.org/abs/2506.01197,https://scholar.google.com/citations?user=HI7IMRYAAAAJ&hl=en,2025,"Muchane, M., Richardson, S., Park, K., & Veitch, V.","Muchane, M., Richardson, S., Park, K., & Veitch, V. (2025). Incorporating hierarchical semantics in sparse autoencoder architectures (arXiv:2506.01197). arXiv.",FALSE
28,Owen Melia,Hardware Acceleration for HPS Algorithms in Two and Three Dimensions,https://arxiv.org/abs/2503.17535,https://scholar.google.com/citations?user=flFf22sAAAAJ&hl=en,2025,"Melia, O., Fortunato, D., Hoskins, J., & Willett, R.","Melia, O., Fortunato, D., Hoskins, J., & Willett, R. (2025). Hardware acceleration for HPS algorithms in two and three dimensions (arXiv:2503.17535). arXiv.",FALSE
29,Owen Melia,Multi-frequency progressive refinement for learned inverse scattering,https://www.sciencedirect.com/science/article/pii/S0021999125000920?via%3Dihub,https://scholar.google.com/citations?user=flFf22sAAAAJ&hl=en,2025,"Melia, O., Tsang, O., Charisopoulos, V., Khoo, Y., Hoskins, J., & Willett, R.","Melia, O., Tsang, O., Charisopoulos, V., Khoo, Y., Hoskins, J., & Willett, R. (2025). Multi-frequency progressive refinement for learned inverse scattering. Journal of Computational Physics, 113809.",TRUE
30,Owen Melia,Rotation-invariant random features provide a strong baseline for machine learning on 3D point clouds,https://arxiv.org/abs/2308.06271,https://scholar.google.com/citations?user=flFf22sAAAAJ&hl=en,2023,"Melia, O., Jonas, E., & Willett, R.","Melia, O., Jonas, E., & Willett, R. (2023). Rotation-invariant random features provide a strong baseline for machine learning on 3D point clouds (arXiv:2308.06271). arXiv.",FALSE
31,Mingxuan Li,HypoEval: Hypothesis-Guided Evaluation for Natural Language Generation,https://arxiv.org/abs/2504.07174,https://scholar.google.com/citations?user=Yw-IQncAAAAJ&hl=en,2025,"Li, M., Li, H., & Tan, C.","Li, M., Li, H., & Tan, C. (2025). HypoEval: Hypothesis-guided evaluation for natural language generation (arXiv:2504.07174). arXiv.",FALSE
32,Mingxuan Li,Literature Meets Data: A Synergistic Approach to Hypothesis Generation,https://arxiv.org/abs/2410.17309,https://scholar.google.com/citations?user=Yw-IQncAAAAJ&hl=en,2024,"Liu, H., Zhou, Y., Li, M., Yuan, C., & Tan, C.","Liu, H., Zhou, Y., Li, M., Yuan, C., & Tan, C. (2024). Literature meets data: A synergistic approach to hypothesis generation (arXiv:2410.17309). arXiv.",FALSE
33,Todd Nief,Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers,https://arxiv.org/abs/2506.20746,https://scholar.google.com/citations?user=I5oa8j4AAAAJ,2025,"Nief, T., Reber, D., Richardson, S., & Holtzman, A.","Nief, T., Reber, D., Richardson, S., & Holtzman, A. (2025). Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers (arXiv:2506.20746). arXiv.",FALSE
34,Dixi Yao,Private Retrieval Augmented Generation with Random Projection,https://openreview.net/forum?id=5DfhoxRPXh,https://scholar.google.com/citations?hl=en&user=6f5HCVAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Yao, D., & Li, T.","Yao, D., & Li, T. (2025). Private Retrieval Augmented Generation with Random Projection. In Proceedings of the ICLR 2025 Workshop on Building Trust in LLMs and LLM Applications: From Guardrails to Explainability to Regulation.",TRUE
35,Aaron Schein,Modeling Latent Underdispersion with Discrete Order Statistics,https://arxiv.org/abs/2507.09032,https://scholar.google.com/citations?hl=en&user=CaHuRsgAAAAJ&view_op=list_works&sortby=pubdate,2025,"Lederman, J., & Schein, A.","Lederman, J., & Schein, A. (2025). Modeling Latent Underdispersion with Discrete Order Statistics. arXiv [Preprint]. arXiv:2507.09032.",FALSE
36,Aaron Schein,Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks,https://arxiv.org/abs/2505.21748,https://scholar.google.com/citations?hl=en&user=CaHuRsgAAAAJ&view_op=list_works&sortby=pubdate,2025,"Hood, J., De Bacco, C., & Schein, A.","Hood, J., De Bacco, C., & Schein, A. (2025). Broad spectrum structure discovery in large-scale higher-order networks. arXiv preprint arXiv:2505.21748.",FALSE
37,Aaron Schein,Layers at similar depths generate similar activations across llm architectures,https://arxiv.org/abs/2504.08775,https://scholar.google.com/citations?hl=en&user=CaHuRsgAAAAJ&view_op=list_works&sortby=pubdate,2025,"Wolfram, C., & Schein, A.","Wolfram, C., & Schein, A. (2025). Layers at similar depths generate similar activations across LLM architectures. arXiv preprint arXiv:2504.08775.",FALSE
38,Tzu-Chen Huang,Deep learning lattice gauge theories,https://journals.aps.org/prb/abstract/10.1103/PhysRevB.110.165133,https://scholar.google.com/citations?hl=en&user=mhU0hqEAAAAJ&view_op=list_works&sortby=pubdate,2024,"Apte, A., Córdova, C., Huang, T.-C., & Ashmore, A.","Apte, A., Córdova, C., Huang, T.-C., & Ashmore, A. (2024). Deep learning lattice gauge theories. Physical Review B, 110(16), 165133.",TRUE
39,Ruoxi Jiang,Nested diffusion models using hierarchical latent priors,https://arxiv.org/abs/2412.05984,https://scholar.google.com/citations?hl=en&user=fbVZpI4AAAAJ&view_op=list_works&sortby=pubdate,2024,"Zhang, X., Jiang, R., Willett, R., & Maire, M.","Zhang, X., Jiang, R., Willett, R., & Maire, M. (2024). Nested Diffusion Models Using Hierarchical Latent Priors. arXiv preprint, arXiv:2412.05984",FALSE
40,Ruoxi Jiang,Training neural operators to preserve invariant measures of chaotic attractors,https://arxiv.org/abs/2306.01187,https://scholar.google.com/citations?hl=en&user=fbVZpI4AAAAJ&view_op=list_works&sortby=pubdate,2023,"Jiang, R., Lu, P. Y., Orlova, E., & Willett, R.","Jiang, R., Lu, P. Y., Orlova, E., & Willett, R. (2023). Training neural operators to preserve invariant measures of chaotic attractors. Advances in Neural Information Processing Systems (NeurIPS 2023). arXiv:2306.01187",FALSE
41,Honglin Bao,Language models surface the unwritten code of science and society,https://arxiv.org/abs/2505.18942,https://scholar.google.com/citations?hl=en&user=pSdfiCYAAAAJ&view_op=list_works&sortby=pubdate,2025,"Bao, H., Wu, S., Choi, J., Mao, Y., & Evans, J. A.","Bao, H., Wu, S., Choi, J., Mao, Y., & Evans, J. A. (2025). Language models surface the unwritten code of science and society. ArXiv preprint arXiv:2505.18942.",FALSE
42,Honglin Bao,Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment,https://arxiv.org/abs/2505.12452,https://scholar.google.com/citations?hl=en&user=pSdfiCYAAAAJ&view_op=list_works&sortby=pubdate,2025,"Wu, S., Bao, H., Kunievsky, N., & Evans, J. A.","Wu, S., Bao, H., Kunievsky, N., & Evans, J. A. (2025). Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment. arXiv preprint arXiv:2505.12452.",FALSE
43,John Hood,The ALCORE Tensor Decomposition for Sparse Count Data,https://proceedings.mlr.press/v238/hood24a.html,https://scholar.google.com/citations?hl=en&user=qhes4BsAAAAJ&view_op=list_works&sortby=pubdate,2024,"Hood, J., & Schein, A. J.","Hood, J., & Schein, A. J. (2024). The ALℓ₀ CORE Tensor Decomposition for Sparse Count Data. In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS 2024) (pp. 4654–4662). PMLR.",TRUE
44,Nikos Ignatiadis,Stein's unbiased risk estimate and Hyvärinen's score matching,https://arxiv.org/abs/2502.20123,https://scholar.google.com/citations?hl=en&user=KH3jpkoAAAAJ&view_op=list_works&sortby=pubdate,2025,"Ghosh, S., Ignatiadis, N., Koehler, F., & Lee, A.","Ghosh, S., Ignatiadis, N., Koehler, F., & Lee, A. (2025). Stein’s unbiased risk estimate and Hyvärinen’s score matching. arXiv preprint arXiv:2502.20123.",FALSE
45,Nikos Ignatiadis,Prediction-Powered Adaptive Shrinkage Estimation,https://arxiv.org/abs/2502.14166,https://scholar.google.com/citations?hl=en&user=KH3jpkoAAAAJ&view_op=list_works&sortby=pubdate,2025,"Li, S., & Ignatiadis, N.","Li, S., & Ignatiadis, N. (2025). Prediction-Powered Adaptive Shrinkage Estimation. arXiv preprint arXiv:2502.14166.",FALSE
46,Sue Parkinson,Relu neural networks with linear layers are biased towards single-and multi-index models,https://epubs.siam.org/doi/abs/10.1137/24M1672158,https://scholar.google.com/citations?hl=en&user=spRkSy4AAAAJ&view_op=list_works&sortby=pubdate,2025,"Parkinson, S., Ongie, G., & Willett, R.","Parkinson, S., Ongie, G., & Willett, R. (2025). Relu neural networks with linear layers are biased towards single- and multi-index models. SIAM Journal on Mathematics of Data Science, 7(2)",TRUE
47,Haokun Liu,Hypobench: Towards systematic and principled benchmarking for hypothesis generation,https://arxiv.org/abs/2504.11524,https://scholar.google.com/citations?hl=en&user=XZaIFNwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Liu, H., Huang, S., Hu, J., Zhou, Y., & Tan, C.","Liu, H., Huang, S., Hu, J., Zhou, Y., & Tan, C. (2025). HypoBench: Towards systematic and principled benchmarking for hypothesis generation",FALSE
48,Haokun Liu,Hypothesis generation with large language models,https://arxiv.org/abs/2404.04326,https://scholar.google.com/citations?hl=en&user=XZaIFNwAAAAJ&view_op=list_works&sortby=pubdate,2024,"Zhou, Y., Liu, H., Srivastava, T., Mei, H., & Tan, C.","Zhou, Y., Liu, H., Srivastava, T., Mei, H., & Tan, C. (2024). Hypothesis generation with large language models. arXiv preprint arXiv:2404.04326.",FALSE
49,Joe Hsu,A machine learning model using clinical notes to identify physician fatigue,https://www.nature.com/articles/s41467-025-60865-4,https://scholar.google.com/citations?hl=en&user=3CGrZdkAAAAJ&view_op=list_works&sortby=pubdate,2025,"Hsu, C.-C., Obermeyer, Z., & Tan, C.","Hsu, C.-C., Obermeyer, Z., & Tan, C. (2025). A machine learning model using clinical notes to identify physician fatigue. Nature Communications, 16(1), 5791. Nature Publishing Group UK.",TRUE
50,Joe Hsu,Clinical Notes Reveal Physician Fatigue,https://arxiv.org/abs/2312.03077,https://scholar.google.com/citations?hl=en&user=3CGrZdkAAAAJ&view_op=list_works&sortby=pubdate,2023,"Hsu, C.-C., Obermeyer, Z., & Tan, C.","Hsu, C.-C., Obermeyer, Z., & Tan, C. (2023). Clinical Notes Reveal Physician Fatigue. arXiv preprint, arXiv:2312.03077.",FALSE
51,Karen Zhou,Quantifying the uniqueness and divisiveness of presidential discourse,https://academic.oup.com/pnasnexus/article/3/10/pgae431/7814873,https://scholar.google.com/citations?hl=en&user=IgomoOoAAAAJ&view_op=list_works&sortby=pubdate,2024,"Zhou, K., Meitus, A. A., Chase, M., Wang, G., Mykland, A., Howell, W., & Tan, C.","Zhou, K., Meitus, A. A., Chase, M., Wang, G., Mykland, A., Howell, W., & Tan, C. (2024). Quantifying the uniqueness and divisiveness of presidential discourse. PNAS Nexus, 3(10), pgae431.",TRUE
52,Chenhao Tan,A Century of Inflation Narratives,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5259107,https://scholar.google.com/citations?hl=en&user=KGMaP18AAAAJ&view_op=list_works&sortby=pubdate,2025,"Heddaya, M., Tan, C., Voigt, R., Zeng, Q., & Zentefis, A.","Heddaya, M., Tan, C., Voigt, R., Zeng, Q., & Zentefis, A. (2025). A century of inflation narratives. Available at SSRN 5259107.",TRUE
53,Trevor Spreadbury,BioMAISx: A Corpus for Aspect-Based Sentiment Analysis of Media Representations of Agricultural Biotechnologies in Africa,https://dl.acm.org/doi/10.1145/3627673.3679152,https://scholar.google.com/citations?hl=en&user=WcDzSCwAAAAJ&view_op=list_works&sortby=pubdate,2024,"Chiril, P., Spreadbury, T., Rock, J. S., Dowd-Uribe, B., & Uminsky, D.","Chiril, P., Spreadbury, T., Rock, J. S., Dowd-Uribe, B., & Uminsky, D. (2024). BioMAISx: A corpus for aspect-based sentiment analysis of media representations of agricultural biotechnologies in Africa. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management (pp. 5338–5342). ACM.",TRUE
54,Trevor Spreadbury,Seeds of Discourse: A Multilingual Corpus of Direct Quotations from African Media on Agricultural Biotechnologies,https://aclanthology.org/2025.findings-naacl.473/,https://scholar.google.com/citations?hl=en&user=WcDzSCwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Chiril, P., Spreadbury, T., Rock, J. S., Dowd-Uribe, B., & Uminsky, D.","Chiril, P., Spreadbury, T., Rock, J. S., Dowd-Uribe, B., & Uminsky, D. (2025). Seeds of discourse: A multilingual corpus of direct quotations from African media on agricultural biotechnologies. Findings of the Association for Computational Linguistics: NAACL 2025.",TRUE
55,Joshua Jackson,Rising Moralization in Social Media Discourse,https://repository.uncw.edu/items/ac618300-6698-4696-835a-52819dec3fc1,https://scholar.google.com/citations?hl=en&user=cqmbIlIAAAAJ&view_op=list_works&sortby=pubdate,2025,"Puryear, C., Brady, W., Jackson, J. C., Leong, Y., & Kteily, N.","Puryear, C., Brady, W., Jackson, J. C., Leong, Y., & Kteily, N. (2025). Rising moralization in social media discourse. OSF Preprints.",TRUE
56,Joshua Jackson,Prejudice Tied to State Centralization in Historical Societies,https://osf.io/zxuth/download,https://scholar.google.com/citations?hl=en&user=cqmbIlIAAAAJ&view_op=list_works&sortby=pubdate,2025,"Dillion, D., Liu, Y., Chen, Y., Watts, J., Zhao, C., Baral, S., Bucker, W., Atari, M., Kteily, N., & Jackson, J. C.","Dillion, D., Liu, Y., Chen, Y., Watts, J., Zhao, C., Baral, S., Bucker, W., Atari, M., Kteily, N., & Jackson, J. C. (2025). Prejudice tied to state centralization in historical societies. OSF Preprints.",TRUE
57,Joshua Jackson,Historical Polarization in Legislative Support for Civil Rights in the United States,https://osf.io/7cqfs/download,https://scholar.google.com/citations?hl=en&user=cqmbIlIAAAAJ&view_op=list_works&sortby=pubdate,2025,"Jackson, J. C., Liu, Y., & Kteily, N. S.","Jackson, J. C., Liu, Y., & Kteily, N. S. (2025). Historical polarization in legislative support for civil rights in the United States. OSF Preprints.",TRUE
58,Daniel Grzenda,Cartesian Equivariant Representations for Learning and Understanding Molecular Orbitals,https://chemrxiv.org/engage/chemrxiv/article-details/680be389e561f77ed4d5ff22,https://scholar.google.com/citations?hl=en&user=mB3oEmEAAAAJ&view_op=list_works&sortby=pubdate,2025,"King, D., Grzenda, D., Zhu, R., Hudson, N., Foster, I., Cheng, B., & Gagliardi, L.","King, D., Grzenda, D., Zhu, R., Hudson, N., Foster, I., Cheng, B., & Gagliardi, L. (2025). Cartesian equivariant representations for learning and understanding molecular orbitals. In Proceedings of ChemRxiv (pp. 1–24). ChemRxiv.",TRUE
59,Daniel Grzenda,MOFA: Discovering Materials for Carbon Capture with a GenAI-and Simulation-Based Workflow,https://arxiv.org/abs/2501.10651,https://scholar.google.com/citations?hl=en&user=mB3oEmEAAAAJ&view_op=list_works&sortby=pubdate,2025,"Yan, X., Hudson, N., Park, H., Grzenda, D., Pauloski, J. G., Schwarting, M., Harb, H., Foreman, S., Knight, C., Gibbs, T., Chard, K., Chaudhuri, S., Tajkhorshid, E., Foster, I., Moosavi, M., Ward, L., & Huerta, E. A.","Yan, X., Hudson, N., Park, H., Grzenda, D., Pauloski, J. G., Schwarting, M., Harb, H., Foreman, S., Knight, C., Gibbs, T., Chard, K., Chaudhuri, S., Tajkhorshid, E., Foster, I., Moosavi, M., Ward, L., & Huerta, E. A. (2025). MOFA: Discovering materials for carbon capture with a GenAI-and simulation-based workflow. arXiv preprint arXiv:2501.10651.",FALSE
60,Daniel Grzenda,Deep Model Merging: The Sister of Neural Network Interpretability--A Survey,https://arxiv.org/abs/2410.12927,https://scholar.google.com/citations?hl=en&user=mB3oEmEAAAAJ&view_op=list_works&sortby=pubdate,2024,"Khan, A., Nief, T., Hudson, N., Sakravadia, M., Grzenda, D., Ajith, A., Pettyjohn, J., Chard, K., & Foster, I.","Khan, A., Nief, T., Hudson, N., Sakravadia, M., Grzenda, D., Ajith, A., Pettyjohn, J., Chard, K., & Foster, I. (2024). Deep model merging: The sister of neural network interpretability—A survey. arXiv preprint arXiv:2410.12927.",FALSE
61,Daniel Grzenda,Sok: On finding common ground in loss landscapes using deep model merging techniques,https://ui.adsabs.harvard.edu/abs/2024arXiv241012927K/abstract,https://scholar.google.com/citations?hl=en&user=mB3oEmEAAAAJ&view_op=list_works&sortby=pubdate,2024,"Khan, A., Nief, T., Hudson, N., Sakarvadia, M., Grzenda, D., Ajith, A., Pettyjohn, J., Chard, K., & Foster, I.","Khan, A., Nief, T., Hudson, N., Sakarvadia, M., Grzenda, D., Ajith, A., Pettyjohn, J., Chard, K., & Foster, I. (2024). Sok: On finding common ground in loss landscapes using deep model merging techniques. arXiv e-prints, arXiv:2410.12927.",TRUE
62,Daniel Grzenda,An Empirical Investigation of Container Building Strategies and Warm Times to Reduce Cold Starts in Scientific Computing Serverless Functions,https://ieeexplore.ieee.org/abstract/document/10678668,https://scholar.google.com/citations?hl=en&user=mB3oEmEAAAAJ&view_op=list_works&sortby=pubdate,2024,"Bauer, A., Gonthier, M., Pan, H., Chard, R., Grzenda, D., Straesser, M., Pauloski, J. G., Kamatar, A., Baughman, M., Hudson, N., Foster, I., & Chard, K.","Bauer, A., Gonthier, M., Pan, H., Chard, R., Grzenda, D., Straesser, M., Pauloski, J. G., Kamatar, A., Baughman, M., Hudson, N., Foster, I., & Chard, K. (2024). An empirical investigation of container building strategies and warm times to reduce cold starts in scientific computing serverless functions. 2024 IEEE 20th International Conference on e-Science (e-Science), 1–10. IEEE.",TRUE
63,Georgeta-Cristina Garbacea,HyPerAlign: Interpretable Personalized LLM Alignment via Hypothesis Generation,https://arxiv.org/abs/2505.00038,https://scholar.google.com/citations?user=302eGI0AAAAJ&hl=en,2025,"Garbacea, C., & Tan, C.","Garbacea, C., & Tan, C. (2025). HyPerAlign: Interpretable personalized LLM alignment via hypothesis generation. arXiv preprint arXiv:2505.00038.",FALSE
64,Georgeta-Cristina Garbacea,Evaluating the Goal-Directedness of Large Language Models,https://arxiv.org/abs/2504.11844,https://scholar.google.com/citations?user=302eGI0AAAAJ&hl=en,2025,"Everitt, T., Garbacea, C., Bellot, A., Richens, J., Papadatos, H., Campos, S., & Shah, R.","Everitt, T., Garbacea, C., Bellot, A., Richens, J., Papadatos, H., Campos, S., & Shah, R. (2025). Evaluating the goal-directedness of large language models. arXiv preprint arXiv:2504.11844.",FALSE
65,Kiho Park,The linear representation hypothesis and the geometry of large language models,https://arxiv.org/abs/2311.03658,google.com/url?q=https://scholar.google.com/citations?hl%3Den%26user%3Df4HcMx8AAAAJ%26view_op%3Dlist_works%26sortby%3Dpubdate&sa=D&source=editors&ust=1757574591790232&usg=AOvVaw2f72OtXeLpSRzLMVqpg6wH,2024,"Park, K., Choe, Y. J., & Veitch, V.","Park, K., Choe, Y. J., & Veitch, V. (2024). The linear representation hypothesis and the geometry of large language models. Proceedings of the 41st International Conference on Machine Learning (ICML 2024). arXiv:2311.03658.",TRUE
66,Will Gao,Latent intrinsics emerge from training to relight,https://proceedings.neurips.cc/paper_files/paper/2024/hash/af79bcbd1d229a527c8f10d8d41c589d-Abstract-Conference.html,https://scholar.google.com/citations?user=SacEpXoAAAAJ&hl=en,2024,"Zhang, X., Gao, W., Jain, S., Maire, M., Forsyth, D., & Bhattad, A.","Zhang, X., Gao, W., Jain, S., Maire, M., Forsyth, D., & Bhattad, A. (2024). Latent intrinsics emerge from training to relight. Advances in Neural Information Processing Systems, 37, 96775–96796.",TRUE
67,Will Gao,Residual connections harm self-supervised abstract feature learning,https://openreview.net/forum?id=ZkboHj8miv,https://scholar.google.com/citations?user=SacEpXoAAAAJ&hl=en,2024,"Zhang, X., Jiang, R., Gao, W., Willett, R., & Maire, M.","Zhang, X., Jiang, R., Gao, W., Willett, R., & Maire, M. (2024). Residual connections harm self-supervised abstract feature learning. CoRR. arXiv:2404.10947.",TRUE
68,Rebecca Willett,Data assimilation with machine learning surrogate models: A case study with FourCastNet,https://journals.ametsoc.org/view/journals/aies/4/3/AIES-D-24-0050.1.xml,https://scholar.google.com/citations?hl=en&user=bGRVPl8AAAAJ&view_op=list_works&sortby=pubdate,2025,"Adrian, M., Sanz-Alonso, D., & Willett, R.","Adrian, M., Sanz-Alonso, D., & Willett, R. (2025). Data assimilation with machine learning surrogate models: A case study with FourCastNet. Artificial Intelligence for the Earth Systems, 4(3), e240050. American Meteorological Society.",TRUE
69,Ari Holtzman,Linearly Decoding Refused Knowledge in Aligned Language Models,https://arxiv.org/abs/2507.00239,https://scholar.google.com/citations?hl=en&user=jtrAdywAAAAJ&view_op=list_works&sortby=pubdate,2025,"Shrivastava, A., & Holtzman, A.","Shrivastava, A., & Holtzman, A. (2025). Linearly decoding refused knowledge in aligned language models. arXiv preprint arXiv:2507.00239.",FALSE
70,Ari Holtzman,AbsenceBench: Language Models Can't Tell What's Missing,https://arxiv.org/abs/2506.11440,https://scholar.google.com/citations?hl=en&user=jtrAdywAAAAJ&view_op=list_works&sortby=pubdate,2025,"Fu, H. Y., Shrivastava, A., Moore, J., West, P., Tan, C., & Holtzman, A.","Fu, H. Y., Shrivastava, A., Moore, J., West, P., Tan, C., & Holtzman, A. (2025). AbsenceBench: Language models can’t tell what’s missing. CoRR. arXiv:2506.11440.",FALSE
71,Yichen (Zach) Wang,Unraveling Misinformation Propagation in LLM Reasoning,https://arxiv.org/abs/2505.18555,https://scholar.google.com/citations?hl=en&user=86XiOcsAAAAJ&view_op=list_works&sortby=pubdate,2025,"Feng, Y., Wang, Y., Cui, S., Faltings, B., Lee, M., & Zhou, J.","Feng, Y., Wang, Y., Cui, S., Faltings, B., Lee, M., & Zhou, J. (2025). Unraveling misinformation propagation in LLM reasoning. CoRR. arXiv:2505.18555.",FALSE
72,Junsol Kim,Linear representations of political perspective emerge in large language models,https://arxiv.org/abs/2503.02080,https://scholar.google.com/citations?hl=en&user=O__9HOwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Kim, J., Evans, J., & Schein, A.","Kim, J., Evans, J., & Schein, A. (2025). Linear representations of political perspective emerge in large language models. In Proceedings of the International Conference on Learning Representations (ICLR 2025, Oral). arXiv:2503.02080.",TRUE
73,Yuan Chang Leong,Emotional arousal enhances narrative memories through functional integration of large-scale brain networks,https://www.biorxiv.org/content/10.1101/2025.03.13.643125v2.abstract,https://scholar.google.com/citations?hl=en&user=An2VxEwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Park, J. S., Gollapudi, K., Ke, J., Nau, M., Pappas, I., & Leong, Y. C.","Park, J. S., Gollapudi, K., Ke, J., Nau, M., Pappas, I., & Leong, Y. C. (2025). Emotional arousal enhances narrative memories through functional integration of large-scale brain networks. bioRxiv, 2025.03.13.643125.",TRUE
74,Yuan Chang Leong,Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models.,https://arxiv.org/abs/2508.10007,https://scholar.google.com/citations?hl=en&user=An2VxEwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Lyu, Y., Combs, D., Neumann, D., & Leong, Y. C.","Lyu, Y., Combs, D., Neumann, D., & Leong, Y. C. (2025). Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models. arXiv preprint arXiv:2508.10007.",FALSE
75,Yuan Chang Leong,A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli,https://arxiv.org/abs/2507.18104,https://scholar.google.com/citations?hl=en&user=An2VxEwAAAAJ&view_op=list_works&sortby=pubdate,2025,"He, Q., & Leong, Y. C.","He, Q., & Leong, Y. C. (2025). A multimodal Seq2Seq Transformer for predicting brain responses to naturalistic stimuli. arXiv preprint arXiv:2507.18104.",FALSE
76,Yuan Chang Leong,Predicting whole-brain neural dynamics from prefrontal cortex functional near-infrared spectroscopy signal during movie-watching,https://academic.oup.com/scan/article/20/1/nsaf043/8123738,https://scholar.google.com/citations?hl=en&user=An2VxEwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Gao, S., Nash, R., Burns, S., & Leong, Y. C.","Gao, S., Nash, R., Burns, S., & Leong, Y. C. (2025). Predicting whole-brain neural dynamics from prefrontal cortex functional near-infrared spectroscopy signal during movie-watching. Social Cognitive and Affective Neuroscience, 20(1), nsaf043. Oxford University Press.",TRUE
77,Yuan Chang Leong,Humans and convolutional neural networks prioritize similar visual features in intuitive physics judgments,https://escholarship.org/uc/item/78c4g1kn,https://scholar.google.com/citations?hl=en&user=An2VxEwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Calabro, R., Bhattacharyya, K., Bainbridge, W., & Leong, Y. C.","Calabro, R., Bhattacharyya, K., Bainbridge, W., & Leong, Y. C. (2025). Humans and convolutional neural networks prioritize similar visual features in intuitive physics judgments. Proceedings of the Annual Meeting of the Cognitive Science Society, 47.",TRUE
78,Yuan Chang Leong,Hostile attribution bias shapes neural synchrony in the left ventromedial prefrontal cortex during ambiguous social narratives,https://www.jneurosci.org/content/44/9/e1252232024.abstract,https://scholar.google.com/citations?hl=en&user=An2VxEwAAAAJ&view_op=list_works&sortby=pubdate,2024,"Lyu, Y., Su, Z., Neumann, D., Meidenbauer, K. L., & Leong, Y. C.","Lyu, Y., Su, Z., Neumann, D., Meidenbauer, K. L., & Leong, Y. C. (2024). Hostile attribution bias shapes neural synchrony in the left ventromedial prefrontal cortex during ambiguous social narratives. Journal of Neuroscience, 44(9). Society for Neuroscience.",TRUE
79,Zihao Wang,Does Editing Provide Evidence for Localization?,https://openreview.net/pdf?id=oZXcwWTCfe,,2024,"Wang, Z., & Veitch, V.","Wang, Z., & Veitch, V. (2024). Does editing provide evidence for localization? ICML 2024 Workshop on Mechanistic Interpretability. OpenReview.",TRUE
80,Zihao Wang,A Unified Causal View of Domain Invariant Representation Learning,https://arxiv.org/abs/2208.06987,,2022,"Wang, Z., & Veitch, V.","Wang, Z., & Veitch, V. (2022). A unified causal view of domain invariant representation learning. arXiv preprint arXiv:2208.06987.",FALSE
81,Sean O'Hagan,Tree Bandits for Generative Bayes,https://arxiv.org/abs/2404.10436,https://scholar.google.com/citations?hl=en&user=XZtvs7YAAAAJ&view_op=list_works&sortby=pubdate,2024,"O'Hagan, S., Kim, J., & Rockova, V.","O'Hagan, S., Kim, J., & Rockova, V. (2024). Tree bandits for generative Bayes. arXiv preprint arXiv:2404.10436.",FALSE
82,Sean O'Hagan,Measurement in the age of llms: An application to ideological scaling,https://arxiv.org/abs/2312.09203,https://scholar.google.com/citations?hl=en&user=XZtvs7YAAAAJ&view_op=list_works&sortby=pubdate,2023,"O’Hagan, S., & Schein, A.","O’Hagan, S., & Schein, A. (2023). Measurement in the age of llms: An application to ideological scaling. arXiv preprint arXiv:2312.09203.",FALSE
83,Tian Li,Efficient Distributed Optimization under Heavy-Tailed Noise,https://arxiv.org/abs/2502.04164,https://scholar.google.com/citations?hl=en&user=8JWoJrAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Lee, S. H., Zaheer, M., & Li, T.","Lee, S. H., Zaheer, M., & Li, T. (2025). Efficient distributed optimization under heavy-tailed noise. arXiv preprint arXiv:2502.04164.",FALSE
84,Tian Li,Tilted Sharpness-Aware Minimization,https://arxiv.org/abs/2410.22656,https://scholar.google.com/citations?hl=en&user=8JWoJrAAAAAJ&view_op=list_works&sortby=pubdate,2024,"Li, T., Zhou, T., & Bilmes, J. A.","Li, T., Zhou, T., & Bilmes, J. A. (2024). Tilted sharpness-aware minimization. arXiv preprint arXiv:2410.22656.",FALSE
85,Tian Li,Efficient adaptive federated optimization,https://arxiv.org/abs/2410.18117,https://scholar.google.com/citations?hl=en&user=8JWoJrAAAAAJ&view_op=list_works&sortby=pubdate,2024,"Lee, S. H., Sharma, S., Zaheer, M., & Li, T.","Lee, S. H., Sharma, S., Zaheer, M., & Li, T. (2024). Efficient adaptive federated optimization. arXiv preprint arXiv:2410.18117.",FALSE
86,Yuanze Liu,"The content, structure, and history of English trait words",https://osf.io/7qkg8_v1?view_only=,,2025,"Liu, Y., Charlesworth, T., Koch, A., Luttrell, A., & Jackson, J. C.","Liu, Y., Charlesworth, T., Koch, A., Luttrell, A., & Jackson, J. C. (2025). The content, structure, and history of English trait words. OSF Preprints.",TRUE
87,Zhao Lyu,Inconsistency of cross-validation for structure learning in Gaussian graphical models,https://proceedings.mlr.press/v238/lyu24a.html,https://scholar.google.com/citations?hl=en&user=hE4BKS8AAAAJ&view_op=list_works&sortby=pubdate,2024,"Lyu, Z., Tai, W. M., Kolar, M., & Aragam, B.","Lyu, Z., Tai, W. M., Kolar, M., & Aragam, B. (2024). Inconsistency of cross-validation for structure learning in Gaussian graphical models. International Conference on Artificial Intelligence and Statistics, 3691–3699. PMLR.",TRUE
88,Ganghua Wang,Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs,https://arxiv.org/abs/2505.03814,https://scholar.google.com/citations?hl=en&user=GpbeNCsAAAAJ&view_op=list_works&sortby=pubdate,2025,"Wang, G., Chen, Z., Li, B., & Xu, H.","Wang, G., Chen, Z., Li, B., & Xu, H. (2025). Cer-eval: Certifiable and cost-efficient evaluation framework for llms. arXiv preprint arXiv:2505.03814.",FALSE
89,Anuj Apte,Deep Learning and Non-Invertible Symmetries in Gauge Theories,https://knowledge.uchicago.edu/record/15055?v=pdf,https://scholar.google.com/citations?hl=en&user=oX_oa18AAAAJ&view_op=list_works&sortby=pubdate,2025,"Apte, A.","Apte, A. (2025). Deep learning and non-invertible symmetries in gauge theories. University of Chicago.",TRUE
90,Mourad Heddaya,A Century of Inflation Narratives,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5259107,https://scholar.google.com/citations?hl=en&user=kp9aJigAAAAJ&view_op=list_works&sortby=pubdate,2025,"Heddaya, M., Tan, C., Voigt, R., Zeng, Q., & Zentefis, A.","Heddaya, M., Tan, C., Voigt, R., Zeng, Q., & Zentefis, A. (2025). A century of inflation narratives. SSRN, 5259107.",TRUE
91,Mourad Heddaya,Casesumm: a large-scale dataset for long-context summarization from us supreme court opinions,https://arxiv.org/abs/2501.00097,https://scholar.google.com/citations?hl=en&user=kp9aJigAAAAJ&view_op=list_works&sortby=pubdate,2024,"Heddaya, M., MacMillan, K., Malani, A., Mei, H., & Tan, C.","Heddaya, M., MacMillan, K., Malani, A., Mei, H., & Tan, C. (2024). Casesumm: A large-scale dataset for long-context summarization from US Supreme Court opinions. arXiv preprint arXiv:2501.00097.",FALSE
92,Mourad Heddaya,Causal Micro-Narratives,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5099137,https://scholar.google.com/citations?hl=en&user=kp9aJigAAAAJ&view_op=list_works&sortby=pubdate,2024,"Zentefis, A., Tan, C., Heddaya, M., Voigt, R., & Zeng, Q.","Zentefis, A., Tan, C., Heddaya, M., Voigt, R., & Zeng, Q. (2024). Causal micro-narratives. SSRN 5099137.",TRUE
93,Yongqiang Sun,"Can AI Weather Models Predict the 2024 Dubai Rainfall, a Regional Grey Swan?",https://ui.adsabs.harvard.edu/abs/2025AMS...10552238S/abstract,https://scholar.google.com/citations?hl=en&user=IoIjsH8AAAAJ&view_op=list_works&sortby=pubdate,2025,"Sun, Y. Q., Hassanzadeh, P., & Shaw, T. A.","Sun, Y. Q., Hassanzadeh, P., & Shaw, T. A. (2025). Can AI weather models predict the 2024 Dubai rainfall, a regional grey swan? 105th Annual AMS Meeting, 105, 452238.",TRUE
94,David Uminsky,Entailment Progressions: A Robust Approach to Evaluating Reasoning Within Larger Discourse,https://aclanthology.org/2025.nodalida-1.66/,https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=ei--1CoAAAAJ&sortby=pubdate,2025,"Shastry, R., Chiril, P., Charney, J., & Uminsky, D.","Shastry, R., Chiril, P., Charney, J., & Uminsky, D. (2025). Entailment progressions: A robust approach to evaluating reasoning within larger discourse. Proceedings of the Joint 25th Nordic Conference on Computational Linguistics and 11th Baltic Conference on Human Language Technologies (NoDaLiDa/Baltic-HLT 2025).",TRUE
95,Dang Nguyen,On the effectiveness and generalization of race representations for debiasing high-stakes decisions,https://arxiv.org/abs/2504.06303,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KGMaP18AAAAJ&sortby=pubdate&citation_for_view=KGMaP18AAAAJ:VL0QpB8kHFEC,2025,"Nguyen, D., & Tan, C.","Nguyen, D., & Tan, C. (2025). On the effectiveness and generalization of race representations for debiasing high-stakes decisions. Second Conference on Language Modeling.",FALSE
