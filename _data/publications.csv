Sr_No,Contact,Paper,Link,Google_Scholar_Link,Year,Author_Names,Citation
1,Vasileios Charisopoulos,Nonlinear tomographic reconstruction via nonsmooth optimization,https://epubs.siam.org/doi/10.1137/24M1678982,https://scholar.google.com/citations?user=X3V6rM8AAAAJ&hl=el,2025,"Charisopoulos, V., & Willett, R.","Charisopoulos, V., & Willett, R. (2025). Nonlinear tomographic reconstruction via nonsmooth optimization. SIAM Journal on Mathematics of Data Science, 7(2), 699–722."
2,Vasileios Charisopoulos,Solving Inverse Problems with Deep Linear Neural Networks: Global Convergence Guarantees for Gradient Descent with Weight Decay,https://arxiv.org/abs/2502.15522,https://scholar.google.com/citations?user=X3V6rM8AAAAJ&hl=el,2025,"Laus, H., Parkinson, S., Charisopoulos, V., Krahmer, F., & Willett, R.","Laus, H., Parkinson, S., Charisopoulos, V., Krahmer, F., & Willett, R. (2025). Solving inverse problems with deep linear neural networks: Global convergence guarantees for gradient descent with weight decay (arXiv preprint arXiv:2502.15522)."
3,David Reber,RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals,https://openreview.net/forum?id=rL3uxe5a0c,https://scholar.google.com/citations?hl=en&user=8MXWn9gAAAAJ&view_op=list_works&sortby=pubdate,2025,"Reber, D., Richardson, S. M., Nief, T., Garbacea, C., & Veitch, V.","Reber, D., Richardson, S. M., Nief, T., Garbacea, C., & Veitch, V. (2025). RATE: Causal explainability of reward models with imperfect counterfactuals. In Proceedings of the Forty-second International Conference on Machine Learning."
4,Yibo Jiang,The geometry of categorical and hierarchical concepts in large language models,https://openreview.net/forum?id=bVTM2QKYuA,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2025,"Park, K., Choe, Y. J., Jiang, Y., & Veitch, V.","Park, K., Choe, Y. J., Jiang, Y., & Veitch, V. (2025). The geometry of categorical and hierarchical concepts in large language models. In Proceedings of the International Conference on Learning Representations (ICLR) (oral presentation)."
5,Yibo Jiang,On the origins of linear representations in large language models,https://proceedings.mlr.press/v235/jiang24d.html,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2024,"Jiang, Y., Rajendran, G., Ravikumar, P. K., Aragam, B., & Veitch, V.","Jiang, Y., Rajendran, G., Ravikumar, P. K., Aragam, B., & Veitch, V. (2024). On the origins of linear representations in large language models. In Proceedings of the 41st International Conference on Machine Learning (pp. 21879–21911). PMLR."
6,Yibo Jiang,Beyond reverse KL: Generalizing direct preference optimization with diverse divergence constraints,https://openreview.net/forum?id=2cRzmWXK9N,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2024,"Wang, C., Jiang, Y., Yang, C., Liu, H., & Chen, Y.","Wang, C., Jiang, Y., Yang, C., Liu, H., & Chen, Y. (2024). Beyond reverse KL: Generalizing direct preference optimization with diverse divergence constraints. In Proceedings of the International Conference on Learning Representations (ICLR) (Spotlight presentation)."
7,Yibo Jiang,Learning nonparametric latent causal graphs with unknown interventions,https://proceedings.neurips.cc/paper_files/paper/2023/file/bdeab378efe6eb289714e2a5abc6ed42-Paper-Conference.pdf,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2023,"Jiang, Y., & Aragam, B.","Jiang, Y., & Aragam, B. (2023). Learning nonparametric latent causal graphs with unknown interventions. In Advances in Neural Information Processing Systems, 36 (NeurIPS 2023)."
8,Yibo Jiang,Uncovering meanings of embeddings via partial orthogonality,https://proceedings.neurips.cc/paper_files/paper/2023/file/65a925049647eab0aa06a9faf1cd470b-Paper-Conference.pdf,https://scholar.google.com/citations?user=hvQo2gQAAAAJ&hl=en,2023,"Jiang, Y., Aragam, B., & Veitch, V.","Jiang, Y., Aragam, B., & Veitch, V. (2023). Uncovering meanings of embeddings via partial orthogonality. In Advances in Neural Information Processing Systems (NeurIPS 2023), 36 (pp. ...)."
9,Chacha Chen,CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation,https://arxiv.org/abs/2505.16325,https://scholar.google.com/citations?hl=zh-TW&user=X1c-e4oAAAAJ&view_op=list_works&sortby=pubdate,2025,"Jiang, Y., Chen, C., Wang, S., Li, F., Tang, Z., Mervak, B. M., Chelala, L., Straus, C. M., Chahine, R., Armato, S. G. III, & Tan, C.","Jiang, Y., Chen, C., Wang, S., Li, F., Tang, Z., Mervak, B. M., Chelala, L., Straus, C. M., Chahine, R., Armato, S. G. III, & Tan, C. (2025). CLEAR: A clinically-grounded tabular framework for radiology report evaluation (arXiv:2505.16325). arXiv."
10,Chacha Chen,Gpt-4v cannot generate radiology reports yet,https://arxiv.org/abs/2407.12176,https://scholar.google.com/citations?hl=zh-TW&user=X1c-e4oAAAAJ&view_op=list_works&sortby=pubdate,2024,"Jiang, Y., Chen, C., Nguyen, D., Mervak, B. M., & Tan, C.","Jiang, Y., Chen, C., Nguyen, D., Mervak, B. M., & Tan, C. (2024). Gpt-4v cannot generate radiology reports yet (arXiv:2407.12176). arXiv."
11,Melissa Adrian,Stabilizing black-box model selection with the inflated argmax.,https://arxiv.org/abs/2410.18268,https://scholar.google.com/citations?hl=en&user=kFcLjtUAAAAJ&view_op=list_works&sortby=pubdate,2024,"Adrian, M., Soloff, J. A., & Willett, R.","Adrian, M., Soloff, J. A., & Willett, R. (2024). Stabilizing black-box model selection with the inflated argmax (arXiv:2410.18268). arXiv."
12,Lin Gui,Concept algebra for (score-based) text-controlled generative models,https://proceedings.neurips.cc/paper_files/paper/2023/file/6f125214c86439d107ccb58e549e828f-Paper-Conference.pdf,https://scholar.google.com/citations?user=88eaL8UAAAAJ&hl=en,2023,"Wang, Z., Gui, L., Negrea, J., & Veitch, V.","Wang, Z., Gui, L., Negrea, J., & Veitch, V. (2023). Concept algebra for (score-based) text-controlled generative models. In Advances in Neural Information Processing Systems (Vol. 36, pp. 35331–35349)."
13,Lin Gui,Bonbon alignment for large language models and the sweetness of best-of-n sampling,https://proceedings.neurips.cc/paper_files/paper/2024/hash/056521a35eacd9d2127b66a7d3c499c5-Abstract-Conference.html,https://scholar.google.com/citations?user=88eaL8UAAAAJ&hl=en,2024,"Gui, L., Gârbacea, C., & Veitch, V.","Gui, L., Gârbacea, C., & Veitch, V. (2024). Bonbon alignment for large language models and the sweetness of best-of-n sampling (arXiv:2406.00832). arXiv"
14,Peter Lu,Hierarchical Implicit Neural Emulators,https://arxiv.org/abs/2506.04528,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2025,"Jiang, R., Zhang, X., Jakhar, K., Lu, P. Y., Hassanzadeh, P., Maire, M., & Willett, R.","Jiang, R., Zhang, X., Jakhar, K., Lu, P. Y., Hassanzadeh, P., Maire, M., & Willett, R. (2025). Hierarchical implicit neural emulators (arXiv:2506.04528). arXiv"
15,Peter Lu,Embed and Emulate: Contrastive representations for simulation-based inference,https://arxiv.org/abs/2409.18402,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2024,"Jiang, R., Lu, P. Y., & Willett, R.","Jiang, R., Lu, P. Y., & Willett, R. (2024). Embed and Emulate: Contrastive representations for simulation-based inference (arXiv:2409.18402). arXiv."
16,Peter Lu,Training Machine Learning Emulators to Preserve Invariant Measures of Chaotic Attractors,https://ui.adsabs.harvard.edu/abs/2024APS..MARS28006L/abstract,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2024,"Lu, P., Jiang, R., Orlova, E., & Willett, R.","Lu, P., Jiang, R., Orlova, E., & Willett, R. (2024). Training machine learning emulators to preserve invariant measures of chaotic attractors. APS March Meeting Abstracts, 2024, S28.006."
17,Peter Lu,Deep Stochastic Mechanics,https://arxiv.org/abs/2305.19685,https://scholar.google.com/citations?hl=en&user=g6PnqoYAAAAJ&view_op=list_works&sortby=pubdate,2023,"Orlova, E., Ustimenko, A., Jiang, R., Lu, P. Y., & Willett, R.","Orlova, E., Ustimenko, A., Jiang, R., Lu, P. Y., & Willett, R. (2023). Deep stochastic mechanics (arXiv:2305.19685). arXiv."
18,Chenghao Yang,How Alignment Shrinks the Generative Horizon,https://arxiv.org/abs/2506.17871,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Yang, C., & Holtzman, A.","Yang, C., & Holtzman, A. (2025). How alignment shrinks the generative horizon (arXiv:2506.17871). arXiv."
19,Chenghao Yang,Tokenized Bandit for LLM Decoding and Alignment,https://icml.cc/virtual/2025/poster/45185,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Shin, S., Yang, C., Xu, H., & Hajiaghayi, M. T.","Shin, S., Yang, C., Xu, H., & Hajiaghayi, M. T. (2025). Tokenized bandit for LLM decoding and alignment. In Proceedings of the 42nd International Conference on Machine Learning (ICML 2025). arXiv:2506.07276."
20,Chenghao Yang,Grounded Persuasive Language Generation for Automated Marketing,https://arxiv.org/abs/2502.16810,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Wu, J., Yang, C., Mahns, S., Wang, C., Zhu, H., Fang, F., & Xu, H.","Wu, J., Yang, C., Mahns, S., Wang, C., Zhu, H., Fang, F., & Xu, H. (2025). Grounded persuasive language generation for automated marketing (arXiv:2502.16810). arXiv."
21,Chenghao Yang,When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models (NAACL 2024 Findings),https://aclanthology.org/2024.findings-naacl.237/,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2024,"Li, Y., Yang, C., & Ettinger, A.","Li, Y., Yang, C., & Ettinger, A. (2024). When hindsight is not 20/20: Testing limits on reflective thinking in large language models. In Findings of the Association for Computational Linguistics: NAACL 2024. arXiv:2404.09129."
22,Chenghao Yang,"Identifying Self-Disclosures of Use, Misuse and Addiction in Community-based Social Media Posts (NAACL 2024 Findings)",https://aclanthology.org/2024.findings-naacl.161/,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2024,"Yang, C., Chakrabarty, T., Hochstatter, K. R., Slavin, M. N., El‑Bassel, N., & Muresan, S.","Yang, C., Chakrabarty, T., Hochstatter, K. R., Slavin, M. N., El‑Bassel, N., & Muresan, S. (2024). Identifying self‑disclosures of use, misuse and addiction in community‑based social media posts. In Findings of the Association for Computational Linguistics: NAACL 2024 (pp. 2507–2521). Association for Computational Linguistics"
23,Chenghao Yang,Can You Follow Me? Testing Situational Understanding in ChatGPT (EMNLP 2023),https://aclanthology.org/2023.emnlp-main.394/,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2023,"Yang, C., & Ettinger, A.","Yang, C., & Ettinger, A. (2023). Can You Follow Me? Testing situational understanding in ChatGPT. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (pp. 6385–6398). Association for Computational Linguistics"
24,Chenghao Yang,Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints (ICLR 2024 Spotlight),https://openreview.net/forum?id=2cRzmWXK9N,https://scholar.google.com/citations?hl=zh-CN&user=B28fiOAAAAAJ&view_op=list_works&sortby=pubdate,2024,"Wang, C., Jiang, Y., Yang, C., Liu, H., & Chen, Y.","Wang, C., Jiang, Y., Yang, C., Liu, H., & Chen, Y. (2024). Beyond Reverse KL: Generalizing direct preference optimization with diverse divergence constraints. In Proceedings of the International Conference on Learning Representations (ICLR 2024)."
25,Xiaoyan Bai,Concept Incongruence: An Exploration of Time and Death in Role Playing,https://arxiv.org/abs/2505.14905,https://scholar.google.com/citations?hl=en&user=ic3BUhMAAAAJ&view_op=list_works&sortby=pubdate,2025,"Bai, X., Peng, I., Singh, A., & Tan, C.","Bai, X., Peng, I., Singh, A., & Tan, C. (2025). Concept incongruence: An exploration of time and death in role playing (arXiv:2505.14905). arXiv"
26,Akhil Premkumar,Diffusion Density Estimators,https://arxiv.org/abs/2410.06986,https://scholar.google.com/citations?hl=en&user=clBdLXkAAAAJ&view_op=list_works&sortby=pubdate,2024,"Premkumar, A.","Premkumar, A. (2024). Diffusion density estimators (arXiv:2410.06986). arXiv."
27,Akhil Premkumar,Neural entropy,https://arxiv.org/abs/2409.03817,https://scholar.google.com/citations?hl=en&user=clBdLXkAAAAJ&view_op=list_works&sortby=pubdate,2024,"Premkumar, A.","Premkumar, A. (2024). Neural entropy (arXiv:2409.03817). arXiv."
28,Mark Muchane,Incorporating Hierarchical Semantics in Sparse Autoencoder Architectures,https://arxiv.org/abs/2506.01197,https://scholar.google.com/citations?user=HI7IMRYAAAAJ&hl=en,2025,"Muchane, M., Richardson, S., Park, K., & Veitch, V.","Muchane, M., Richardson, S., Park, K., & Veitch, V. (2025). Incorporating hierarchical semantics in sparse autoencoder architectures (arXiv:2506.01197). arXiv."
29,Xiaoyan Bai,Concept Incongruence: An Exploration of Time and Death in Role Playing,https://arxiv.org/abs/2505.14905,https://scholar.google.com/citations?hl=en&user=ic3BUhMAAAAJ&view_op=list_works&sortby=pubdate,2025,"Bai, X., Peng, I., Singh, A., & Tan, C.","Bai, X., Peng, I., Singh, A., & Tan, C. (2025). Concept incongruence: An exploration of time and death in role playing (arXiv:2505.14905). arXiv."
30,Owen Melia,Hardware Acceleration for HPS Algorithms in Two and Three Dimensions,https://arxiv.org/abs/2503.17535,https://scholar.google.com/citations?user=flFf22sAAAAJ&hl=en,2025,"Melia, O., Fortunato, D., Hoskins, J., & Willett, R.","Melia, O., Fortunato, D., Hoskins, J., & Willett, R. (2025). Hardware acceleration for HPS algorithms in two and three dimensions (arXiv:2503.17535). arXiv."
31,Owen Melia,Multi-frequency progressive refinement for learned inverse scattering,https://www.sciencedirect.com/science/article/pii/S0021999125000920?via%3Dihub,https://scholar.google.com/citations?user=flFf22sAAAAJ&hl=en,2025,"Melia, O., Tsang, O., Charisopoulos, V., Khoo, Y., Hoskins, J., & Willett, R.","Melia, O., Tsang, O., Charisopoulos, V., Khoo, Y., Hoskins, J., & Willett, R. (2025). Multi-frequency progressive refinement for learned inverse scattering. Journal of Computational Physics, 113809."
32,Owen Melia,Rotation-invariant random features provide a strong baseline for machine learning on 3D point clouds,https://arxiv.org/abs/2308.06271,https://scholar.google.com/citations?user=flFf22sAAAAJ&hl=en,2023,"Melia, O., Jonas, E., & Willett, R.","Melia, O., Jonas, E., & Willett, R. (2023). Rotation-invariant random features provide a strong baseline for machine learning on 3D point clouds (arXiv:2308.06271). arXiv."
33,Mingxuan Li,HypoEval: Hypothesis-Guided Evaluation for Natural Language Generation,https://arxiv.org/abs/2504.07174,https://scholar.google.com/citations?user=Yw-IQncAAAAJ&hl=en,2025,"Li, M., Li, H., & Tan, C.","Li, M., Li, H., & Tan, C. (2025). HypoEval: Hypothesis-guided evaluation for natural language generation (arXiv:2504.07174). arXiv."
34,Mingxuan Li,Literature Meets Data: A Synergistic Approach to Hypothesis Generation,https://arxiv.org/abs/2410.17309,https://scholar.google.com/citations?user=Yw-IQncAAAAJ&hl=en,2024,"Liu, H., Zhou, Y., Li, M., Yuan, C., & Tan, C.","Liu, H., Zhou, Y., Li, M., Yuan, C., & Tan, C. (2024). Literature meets data: A synergistic approach to hypothesis generation (arXiv:2410.17309). arXiv."
35,Todd Nief,Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers,https://arxiv.org/abs/2506.20746,https://scholar.google.com/citations?user=I5oa8j4AAAAJ,2025,"Nief, T., Reber, D., Richardson, S., & Holtzman, A.","Nief, T., Reber, D., Richardson, S., & Holtzman, A. (2025). Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers (arXiv:2506.20746). arXiv."
36,Todd Nief,RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals,https://arxiv.org/abs/2410.11348,https://scholar.google.com/citations?user=I5oa8j4AAAAJ,2025,"Reber, D., Richardson, S. M., Nief, T., Garbacea, C., & Veitch, V.","Reber, D., Richardson, S. M., Nief, T., Garbacea, C., & Veitch, V. (2025). RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals. In Proceedings of the Forty-second International Conference on Machine Learning (ICML 2025)."
37,Dixi Yao,Private Retrieval Augmented Generation with Random Projection,https://openreview.net/forum?id=5DfhoxRPXh,https://scholar.google.com/citations?hl=en&user=6f5HCVAAAAAJ&view_op=list_works&sortby=pubdate,2025,"Yao, D., & Li, T.","Yao, D., & Li, T. (2025). Private Retrieval Augmented Generation with Random Projection. In Proceedings of the ICLR 2025 Workshop on Building Trust in LLMs and LLM Applications: From Guardrails to Explainability to Regulation."
38,Aaron Schein,Modeling Latent Underdispersion with Discrete Order Statistics,https://arxiv.org/abs/2507.09032,https://scholar.google.com/citations?hl=en&user=CaHuRsgAAAAJ&view_op=list_works&sortby=pubdate,2025,"Lederman, J., & Schein, A.","Lederman, J., & Schein, A. (2025). Modeling Latent Underdispersion with Discrete Order Statistics. arXiv [Preprint]. arXiv:2507.09032."
39,Aaron Schein,Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks,https://arxiv.org/abs/2505.21748,https://scholar.google.com/citations?hl=en&user=CaHuRsgAAAAJ&view_op=list_works&sortby=pubdate,2025,"Hood, J., De Bacco, C., & Schein, A.","Hood, J., De Bacco, C., & Schein, A. (2025). Broad spectrum structure discovery in large-scale higher-order networks. arXiv preprint arXiv:2505.21748."
40,Aaron Schein,Layers at similar depths generate similar activations across llm architectures,https://arxiv.org/abs/2504.08775,https://scholar.google.com/citations?hl=en&user=CaHuRsgAAAAJ&view_op=list_works&sortby=pubdate,2025,"Wolfram, C., & Schein, A.","Wolfram, C., & Schein, A. (2025). Layers at similar depths generate similar activations across LLM architectures. arXiv preprint arXiv:2504.08775."
41,Tzu-Chen Huang,Deep learning lattice gauge theories,https://journals.aps.org/prb/abstract/10.1103/PhysRevB.110.165133,https://scholar.google.com/citations?hl=en&user=mhU0hqEAAAAJ&view_op=list_works&sortby=pubdate,2024,"Apte, A., Córdova, C., Huang, T.-C., & Ashmore, A.","Apte, A., Córdova, C., Huang, T.-C., & Ashmore, A. (2024). Deep learning lattice gauge theories. Physical Review B, 110(16), 165133."
48,Honglin Bao,Language models surface the unwritten code of science and society,https://arxiv.org/abs/2505.18942,https://scholar.google.com/citations?hl=en&user=pSdfiCYAAAAJ&view_op=list_works&sortby=pubdate,2025,"Bao, H., Wu, S., Choi, J., Mao, Y., & Evans, J. A.","Bao, H., Wu, S., Choi, J., Mao, Y., & Evans, J. A. (2025). Language models surface the unwritten code of science and society. ArXiv preprint arXiv:2505.18942."
49,Honglin Bao,Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment,https://arxiv.org/abs/2505.12452,https://scholar.google.com/citations?hl=en&user=pSdfiCYAAAAJ&view_op=list_works&sortby=pubdate,2025,"Wu, S., Bao, H., Kunievsky, N., & Evans, J. A.","Wu, S., Bao, H., Kunievsky, N., & Evans, J. A. (2025). Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment. arXiv preprint arXiv:2505.12452."
50,John Hood,Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks,https://arxiv.org/abs/2505.21748,https://scholar.google.com/citations?hl=en&user=qhes4BsAAAAJ&view_op=list_works&sortby=pubdate,2025,"Hood, J., De Bacco, C., & Schein, A.","Hood, J., De Bacco, C., & Schein, A. (2025). Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks. arXiv preprint arXiv:2505.21748."
51,John Hood,The ALCORE Tensor Decomposition for Sparse Count Data,https://proceedings.mlr.press/v238/hood24a.html,https://scholar.google.com/citations?hl=en&user=qhes4BsAAAAJ&view_op=list_works&sortby=pubdate,2024,"Hood, J., & Schein, A. J.","Hood, J., & Schein, A. J. (2024). The ALℓ₀ CORE Tensor Decomposition for Sparse Count Data. In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS 2024) (pp. 4654–4662). PMLR."
52,Nikos Ignatiadis,Stein's unbiased risk estimate and Hyvärinen's score matching,https://arxiv.org/abs/2502.20123,https://scholar.google.com/citations?hl=en&user=KH3jpkoAAAAJ&view_op=list_works&sortby=pubdate,2025,"Ghosh, S., Ignatiadis, N., Koehler, F., & Lee, A.","Ghosh, S., Ignatiadis, N., Koehler, F., & Lee, A. (2025). Stein’s unbiased risk estimate and Hyvärinen’s score matching. arXiv preprint arXiv:2502.20123."
53,Nikos Ignatiadis,Prediction-Powered Adaptive Shrinkage Estimation,https://arxiv.org/abs/2502.14166,https://scholar.google.com/citations?hl=en&user=KH3jpkoAAAAJ&view_op=list_works&sortby=pubdate,2025,"Li, S., & Ignatiadis, N.","Li, S., & Ignatiadis, N. (2025). Prediction-Powered Adaptive Shrinkage Estimation. arXiv preprint arXiv:2502.14166."
54,Sue Parkinson,Relu neural networks with linear layers are biased towards single-and multi-index models,https://epubs.siam.org/doi/abs/10.1137/24M1672158,https://scholar.google.com/citations?hl=en&user=spRkSy4AAAAJ&view_op=list_works&sortby=pubdate,2025,"Parkinson, S., Ongie, G., & Willett, R.","Parkinson, S., Ongie, G., & Willett, R. (2025). Relu neural networks with linear layers are biased towards single- and multi-index models. SIAM Journal on Mathematics of Data Science, 7(2)"
55,Haokun Liu,Hypobench: Towards systematic and principled benchmarking for hypothesis generation,https://arxiv.org/abs/2504.11524,https://scholar.google.com/citations?hl=en&user=XZaIFNwAAAAJ&view_op=list_works&sortby=pubdate,2025,"Liu, H., Huang, S., Hu, J., Zhou, Y., & Tan, C.","Liu, H., Huang, S., Hu, J., Zhou, Y., & Tan, C. (2025). HypoBench: Towards systematic and principled benchmarking for hypothesis generation"
56,Haokun Liu,Literature meets data: A synergistic approach to hypothesis generation,https://arxiv.org/abs/2410.17309,https://scholar.google.com/citations?hl=en&user=XZaIFNwAAAAJ&view_op=list_works&sortby=pubdate,2024,"Liu, H., Zhou, Y., Li, M., Yuan, C., & Tan, C.","Liu, H., Zhou, Y., Li, M., Yuan, C., & Tan, C. (2024). Literature meets data: A synergistic approach to hypothesis generation. arXiv preprint arXiv:2410.17309."
57,Haokun Liu,Hypothesis generation with large language models,https://arxiv.org/abs/2404.04326,https://scholar.google.com/citations?hl=en&user=XZaIFNwAAAAJ&view_op=list_works&sortby=pubdate,2024,"Zhou, Y., Liu, H., Srivastava, T., Mei, H., & Tan, C.","Zhou, Y., Liu, H., Srivastava, T., Mei, H., & Tan, C. (2024). Hypothesis generation with large language models. arXiv preprint arXiv:2404.04326."
